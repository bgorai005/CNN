{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrDOIMiMZNCC"
      },
      "source": [
        "# Hospital Readmission Prediction - Feature Engineering\n",
        "\n",
        "This notebook focuses on feature engineering for the hospital readmission prediction model. We'll transform raw features into more informative ones and prepare the data for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-OU6-2YZNCE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('Set2')\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHQMcGJAZNCF"
      },
      "source": [
        "## 1. Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQACXwpWZNCF"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('diabetic_data.csv')\n",
        "print(f\"Dataset shape: {data.shape}\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR_VhZrJZNCG"
      },
      "source": [
        "## 2. Basic Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNPvdEPYZNCG"
      },
      "outputs": [],
      "source": [
        "# Replace '?' with NaN for uniformity\n",
        "df = df.replace('?', np.nan)\n",
        "\n",
        "# Drop high-missing columns\n",
        "missing_threshold = 0.4\n",
        "high_missing = df.columns[df.isnull().mean() > missing_threshold]\n",
        "df.drop(columns=high_missing, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remaining columns who has missing vlaues\n",
        "missing_percent = df.isna().mean() * 100\n",
        "missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
        "print(missing_percent)\n"
      ],
      "metadata": {
        "id": "eZtCIaJvvS6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yydBy2sKv1eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcLnbxvaZNCH"
      },
      "source": [
        "## 3. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vaby9ALCZNCH"
      },
      "outputs": [],
      "source": [
        "# 3.1 Extract temporal features\n",
        "df['admission_month'] = df['admission_date'].dt.month\n",
        "df['admission_day_of_week'] = df['admission_date'].dt.dayofweek\n",
        "df['admission_quarter'] = df['admission_date'].dt.quarter\n",
        "df['is_weekend_admission'] = df['admission_day_of_week'].isin([5, 6]).astype(int)\n",
        "\n",
        "# Visualize readmission rate by day of week\n",
        "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "day_readmission = df.groupby('admission_day_of_week')['readmission_30d'].mean() * 100\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "day_readmission.plot(kind='bar')\n",
        "plt.title('Readmission Rate by Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Readmission Rate (%)')\n",
        "plt.xticks(range(7), day_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48rDiCARZNCI"
      },
      "outputs": [],
      "source": [
        "# 3.2 Create age groups\n",
        "bins = [0, 40, 65, 75, 100]\n",
        "labels = ['<40', '40-65', '65-75', '>75']\n",
        "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels)\n",
        "\n",
        "# Visualize readmission rate by age group\n",
        "age_group_readmission = df.groupby('age_group')['readmission_30d'].mean() * 100\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "age_group_readmission.plot(kind='bar')\n",
        "plt.title('Readmission Rate by Age Group')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Readmission Rate (%)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gSdIxWCZNCJ"
      },
      "outputs": [],
      "source": [
        "# 3.3 Create interaction features\n",
        "df['age_heart_failure'] = df['age'] * df['heart_failure']\n",
        "df['age_diabetes'] = df['age'] * df['diabetes']\n",
        "df['previous_emergency'] = df['previous_admissions'] * df['emergency_admission']\n",
        "df['medication_count_adherence'] = df['medication_count'] * df['medication_adherence']\n",
        "df['comorbidity_count'] = df[['diabetes', 'heart_failure', 'copd', 'hypertension', 'renal_disease']].sum(axis=1)\n",
        "\n",
        "# Visualize readmission rate by comorbidity count\n",
        "comorbidity_readmission = df.groupby('comorbidity_count')['readmission_30d'].mean() * 100\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "comorbidity_readmission.plot(kind='bar')\n",
        "plt.title('Readmission Rate by Number of Comorbidities')\n",
        "plt.xlabel('Number of Comorbidities')\n",
        "plt.ylabel('Readmission Rate (%)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXac-Z7uZNCK"
      },
      "outputs": [],
      "source": [
        "# 3.4 Create risk score based on domain knowledge\n",
        "df['risk_score'] = (\n",
        "    0.2 * (df['age'] > 75).astype(int) +\n",
        "    0.15 * df['diabetes'] +\n",
        "    0.25 * df['heart_failure'] +\n",
        "    0.2 * df['copd'] +\n",
        "    0.1 * df['renal_disease'] +\n",
        "    0.05 * (df['previous_admissions'] > 2).astype(int) +\n",
        "    0.15 * (df['medication_count'] > 8).astype(int) -\n",
        "    0.3 * df['medication_adherence'] +\n",
        "    0.1 * df['emergency_admission'] +\n",
        "    0.1 * (df['discharge_disposition'] == 2).astype(int)\n",
        ")\n",
        "\n",
        "# Visualize risk score distribution by readmission status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df, x='risk_score', hue='readmission_30d', bins=30, multiple='dodge')\n",
        "plt.title('Risk Score Distribution by Readmission Status')\n",
        "plt.xlabel('Risk Score')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(['Not Readmitted', 'Readmitted'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZtIUZJEZNCK"
      },
      "outputs": [],
      "source": [
        "# 3.5 One-hot encode categorical variables\n",
        "df_encoded = pd.get_dummies(df, columns=['gender', 'age_group', 'primary_diagnosis', 'discharge_disposition'], drop_first=True)\n",
        "\n",
        "print(f\"Shape after one-hot encoding: {df_encoded.shape}\")\n",
        "print(f\"New features added: {df_encoded.shape[1] - df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQqlLhOKZNCL"
      },
      "source": [
        "## 4. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_BH_eK6ZNCL"
      },
      "outputs": [],
      "source": [
        "# Prepare data for feature selection\n",
        "# Drop non-feature columns\n",
        "X = df_encoded.drop(columns=['patient_id', 'admission_date', 'discharge_date', 'readmission_30d', 'days_to_readmission'])\n",
        "y = df_encoded['readmission_30d']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYe72chfZNCM"
      },
      "outputs": [],
      "source": [
        "# 4.1 Feature importance using Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Plot the top 20 features\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title('Feature Importances')\n",
        "plt.bar(range(20), importances[indices][:20], align='center')\n",
        "plt.xticks(range(20), X.columns[indices][:20], rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print top 20 features\n",
        "print(\"Top 20 features by importance:\")\n",
        "for i in range(20):\n",
        "    print(f\"{i+1}. {X.columns[indices][i]}: {importances[indices][i]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aPMCVBuZNCM"
      },
      "outputs": [],
      "source": [
        "# 4.2 Statistical feature selection using ANOVA F-value\n",
        "selector = SelectKBest(f_classif, k=20)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Get selected feature names\n",
        "mask = selector.get_support()\n",
        "selected_features = X.columns[mask]\n",
        "\n",
        "# Get scores\n",
        "scores = selector.scores_\n",
        "selected_scores = scores[mask]\n",
        "\n",
        "# Sort by score\n",
        "sorted_indices = np.argsort(selected_scores)[::-1]\n",
        "sorted_features = selected_features[sorted_indices]\n",
        "sorted_scores = selected_scores[sorted_indices]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title('Feature Selection using ANOVA F-value')\n",
        "plt.bar(range(len(sorted_features)), sorted_scores, align='center')\n",
        "plt.xticks(range(len(sorted_features)), sorted_features, rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Top 20 features by ANOVA F-value:\")\n",
        "for i, (feature, score) in enumerate(zip(sorted_features, sorted_scores)):\n",
        "    print(f\"{i+1}. {feature}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIrK45I9ZNCN"
      },
      "outputs": [],
      "source": [
        "# 4.3 Recursive Feature Elimination (RFE)\n",
        "rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=20)\n",
        "rfe.fit(X, y)\n",
        "\n",
        "# Get selected feature names\n",
        "rfe_mask = rfe.get_support()\n",
        "rfe_features = X.columns[rfe_mask]\n",
        "\n",
        "print(\"Top 20 features selected by RFE:\")\n",
        "for i, feature in enumerate(rfe_features):\n",
        "    print(f\"{i+1}. {feature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhgqB2W1ZNCO"
      },
      "source": [
        "## 5. Compare Feature Selection Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB_oUZzNZNCO"
      },
      "outputs": [],
      "source": [
        "# Compare the features selected by different methods\n",
        "rf_features = X.columns[indices][:20]\n",
        "anova_features = sorted_features\n",
        "\n",
        "# Find common features\n",
        "common_all = set(rf_features) & set(anova_features) & set(rfe_features)\n",
        "common_rf_anova = set(rf_features) & set(anova_features)\n",
        "common_rf_rfe = set(rf_features) & set(rfe_features)\n",
        "common_anova_rfe = set(anova_features) & set(rfe_features)\n",
        "\n",
        "print(f\"Features common to all methods: {len(common_all)}\")\n",
        "print(f\"Features common to RF and ANOVA: {len(common_rf_anova)}\")\n",
        "print(f\"Features common to RF and RFE: {len(common_rf_rfe)}\")\n",
        "print(f\"Features common to ANOVA and RFE: {len(common_anova_rfe)}\")\n",
        "\n",
        "print(\"\\nFeatures common to all methods:\")\n",
        "for feature in common_all:\n",
        "    print(f\"- {feature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toVdwlfHZNCO"
      },
      "source": [
        "## 6. Final Feature Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOQVf3jnZNCO"
      },
      "outputs": [],
      "source": [
        "# Create a final feature set based on the analysis\n",
        "# We'll use features that appear in at least 2 of the 3 methods\n",
        "all_selected_features = list(rf_features) + list(anova_features) + list(rfe_features)\n",
        "feature_counts = pd.Series(all_selected_features).value_counts()\n",
        "final_features = feature_counts[feature_counts >= 2].index.tolist()\n",
        "\n",
        "print(f\"Final feature set size: {len(final_features)}\")\n",
        "print(\"\\nFinal features:\")\n",
        "for feature in final_features:\n",
        "    print(f\"- {feature}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ugfs6YjZNCP"
      },
      "outputs": [],
      "source": [
        "# Create the final feature matrix\n",
        "X_final = X[final_features]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_final)\n",
        "\n",
        "# Convert back to DataFrame for better visualization\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X_final.columns)\n",
        "\n",
        "print(f\"Final scaled feature matrix shape: {X_scaled_df.shape}\")\n",
        "X_scaled_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g4z9GddZNCP"
      },
      "source": [
        "## 7. Save Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoF0cduzZNCP"
      },
      "outputs": [],
      "source": [
        "# Save the final feature set for reference\n",
        "import os\n",
        "os.makedirs('../data/features', exist_ok=True)\n",
        "\n",
        "# Save the list of final features\n",
        "with open('../data/features/final_features.txt', 'w') as f:\n",
        "    for feature in final_features:\n",
        "        f.write(f\"{feature}\\n\")\n",
        "\n",
        "print(f\"Final feature list saved to ../data/features/final_features.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ME_49knZNCQ"
      },
      "outputs": [],
      "source": [
        "# Save the full processed dataset\n",
        "# Add the target variable back\n",
        "X_scaled_df['readmission_30d'] = y.values\n",
        "\n",
        "# Save to CSV\n",
        "X_scaled_df.to_csv('../data/features/processed_features.csv', index=False)\n",
        "print(f\"Processed features saved to ../data/features/processed_features.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJor7AqZZNCQ"
      },
      "source": [
        "## 8. Summary of Feature Engineering\n",
        "\n",
        "In this notebook, we performed several feature engineering steps:\n",
        "\n",
        "1. **Temporal Features**:\n",
        "   - Extracted month, day of week, and quarter from admission date\n",
        "   - Created a weekend admission indicator\n",
        "\n",
        "2. **Categorical Transformations**:\n",
        "   - Created age groups\n",
        "   - One-hot encoded categorical variables\n",
        "\n",
        "3. **Interaction Features**:\n",
        "   - Combined age with medical conditions\n",
        "   - Created previous emergency admissions\n",
        "   - Combined medication count and adherence\n",
        "   - Created comorbidity count\n",
        "\n",
        "4. **Domain Knowledge Features**:\n",
        "   - Created a risk score based on clinical factors\n",
        "\n",
        "5. **Feature Selection**:\n",
        "   - Used Random Forest importance\n",
        "   - Applied ANOVA F-value selection\n",
        "   - Performed Recursive Feature Elimination\n",
        "   - Selected features that appeared in at least 2 methods\n",
        "\n",
        "6. **Feature Scaling**:\n",
        "   - Standardized the final feature set\n",
        "\n",
        "The final feature set includes a mix of demographic, medical, temporal, and interaction features that show strong predictive power for hospital readmissions."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}